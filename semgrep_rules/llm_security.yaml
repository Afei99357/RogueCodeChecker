rules:
  - id: llm-untrusted-input-into-prompt
    message: Untrusted input flows into LLM prompt content
    severity: WARNING
    languages: [python]
    metadata:
      category: llm
      cwe: CWE-20
      description: User input is passed directly to LLM prompt without validation/sanitization
    patterns:
      - pattern-inside: |
          $X = input(...)
          ...
          openai.ChatCompletion.create(...)
      - pattern-either:
          - pattern: openai.ChatCompletion.create(..., messages=[..., {"content": $X, ...}, ...], ...)
          - pattern: openai.ChatCompletion.create(..., prompt=$X, ...)

  - id: llm-exec-model-output
    message: Executing LLM output is dangerous
    severity: ERROR
    languages: [python]
    metadata:
      category: llm
      cwe: CWE-94
      description: Model output used as code/command execution
    pattern-inside: |
      $R = openai.ChatCompletion.create(...)
      ...
      $C = $R["choices"][0]["message"]["content"]
      ...
      $SINK($C)
    pattern-either:
      - pattern: eval($C)
      - pattern: exec($C)
      - pattern: subprocess.run($C, ...)
      - pattern: os.system($C)

